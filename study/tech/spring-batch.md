# 우리 배치는 정말 필요해서 만든건가?

## 이 글을 작성하게 된 이유

Redis ZSET은 일간 랭킹을 위한 꽤 괜찮은 도구였습니다.\
조회·좋아요·구매 이벤트가 Kafka를 타고 들어오면 점수로 환산되고, 정렬까지 끝난 상태로 Redis에 쌓입니다.

사용자들은 스크롤을 내릴 때마다 최신 순위를 확인하고, 자정 직후처럼 데이터가 비어있을 땐 Fallback 전략으로 빈 화면을 피했습니다. 여기까지는 실시간성과 사용자 경험을 모두 잡은, 만족스러운 결과였습니다.

문제는 여기서 한 걸음 더 나아가 **주간/월간 랭킹**이 필요해졌다는 점이었습니다.\
일간 랭킹이 잘 돌아가니, 자연스럽게 “지금 구조 그대로 주간·월간까지 확장할 수 있을까?”라는 질문이 떠올랐습니다.\
이번 주 TOP 100, 이번 달 TOP 100 ... 실시간성보다는 통계적인 성격이 강하지만, \
여전히 사용자는 빠른 응답을 기대합니다.

하지만 통계적 집계의 본질을 다시 돌아봤습니다.\
주간·월간 랭킹은 이미 쌓여있는 과거 데이터를 모아 다시 줄을 세우는 작업입니다.\
이벤트가 하나 발생할 때마다 매번 7일치, 30일치 점수를 다시 계산하는 건 명백한 낭비였습니다.\
실시간성을 조금 내려놓더라도, **정확성과 효율성**을 챙겨야 했습니다.

그래서 대규모 데이터 집계에 더 어울리는 Spring Batch 를 선택했습니다.\
Chunk 파이프라인을 통해 7일치, 30일치 데이터를 깔끔하게 집계하고, 그 결과를 \
MV(Materialized View)에 영구 저장하는 방식을 택했습니다.\
요청 시에는 미리 만들어진 MV를 읽어 빠르게 응답하고 redis 에 hit 하는 과정 까지 처리했습니다.

구현을 마쳤지만, 마음 한구석에는 여전히 의구심이 남았습니다.

> “새로운 통계 요구가 나올 때마다, 매번 이렇게 새로운 Job을 만들어야 할까?”\
> “단순한 쿼리나 스크립트로는 안 될까? 배치는 과잉 설계가 아닐까?”

RDB 풀스캔이 가져올 성능 저하, Cron 스크립트의 복구 어려움을 검토하며 고민 끝에 결론을 내렸습니다.\
이 글은 **실시간성과 통계 사이의 경계**를 긋고, 그 사이에서 **배치라는 도구를 선택하게 된 납득의 과정**입니다.

## 1. 주간 랭킹, Redis 항아리의 깨짐 <a href="#id-1---redis" id="id-1---redis"></a>

일간 랭킹은 Redis ZSET으로 기대했던대로 동작했습니다.\
조회, 좋아요, 구매 이벤트가 발생할 때마다 실시간으로 점수가 반영되고, 짧은 응답속도로 순위가 나옵니다.\
이 성공 경험을 바탕으로, 주간 랭킹 요구사항이 왔을 때 가장 먼저 든 생각은 단순했습니다.

> "키(Key)만 `weekly`로 바꿔서 똑같이 하면 되지 않을까?"

기술적으로는 가능합니다. Redis의 ZSET은 순위를 매기는 데 특화되어 있었으니까 문제가 없을것이라 생각했습니다.\
그렇지만 **"지속 가능한 서비스"** 관점에서 고민을 했습니다.

### 1. 감당할 수 없는 무게 (Memory & Cost)

Redis니까 메모리 좀 쓰면 되지 않나?" 싶지만, 내부를 들여다보면 이야기가 다릅니다. ​ ​

#### **Redis ZSET 메모리 오버헤드 (120byte+ per element)**

* Redis ZSET은 빠른 범위 검색(`O(logN)`)과 조회(`O(1)`)를 위해 **SkipList**와 **HashTable**을 동시에 유지 ​&#x20;
* 이로 인해 실제 데이터(Member + Score) 외에도 **포인터(Pointer), 메타데이터** 등 오버헤드 발생.
* 벤치마크에 따르면 ZSET의 원소 하나당 추가 오버헤드는 약 **120\~130 bytes 발생**. (키 이름 길이 제외)

#### **Ziplist vs Skiplist (메모리 최적화 한계)**

* 원소 개수가 적을 때(기본 128개 미만)는 `ziplist`를 써서 메모리를 아끼지만, 10만 개 수준이면 무조건 **`Skiplist`**&#xB85C; 변환되어 메모리 사용량 급증
* Skiplist 구조는 포인터가 많아 64비트 시스템에서 메모리를 많이 사용

결국 "이번 주 인기 상품" 하나를 위해, 우리는 가장 비싸고 확장이 어려운 인프라 구조를 선택하게 되는 셈이었습니다.

### 깨지면 다시 붙일 수 없다 (영속성)

더 치명적인 건 **데이터의 지속성**이었습니다.\
Redis는 본질적으로 인메모리(In-Memory) 저장소입니다. 빠르지만, 휘발성입니다.

만약 배포 중에 Redis 서버가 재시작된다면?\
일간 랭킹이야 "잠깐 랭킹이 비었습니다" 하고 넘어가거나, 오늘 쌓인 데이터만 다시 계산하면 됩니다.\
하지만 주간 랭킹이 날아가면, **지난 6일치 10만 개 상품의 모든 이벤트**를 다시 읽어서 계산해야 합니다.



결론적으로 봤을때 Redis라는 항아리는"지금 이 순간" 을 담는 데는 최고지만, "일주일의 역사" 를 담기엔 너무 \
비싸다는 의식을 하였습니다.

네, \*\*"운영팀의 피드백"\*\*이라는 가상의 상황을 제거하고, **개발자 스스로 시스템의 안정성을 고민하는 관점**으로 수정하겠습니다.

단순 스크립트(Cron)는 구현이 빠르지만, \*\*"실패했을 때의 대처"\*\*와 **"과거 데이터 처리(Backfill)"** 로직을 직접 짜야 한다는 점에서 결국 \*\*"배치 프레임워크를 흉내 내는 스파게티 코드"\*\*가 되기 쉽습니다. 이 기술적 부채에 초점을 맞췄습니다.

***

## 2. RDB와 스크립트의 유혹: 단순함이라는 부채 <a href="#id-2-rdb" id="id-2-rdb"></a>

Redis라는 값비싼 항아리를 내려놓고 나니, 가장 먼저 눈에 들어온 건 RDB였습니다.\
&#xNAN;**"데이터가 이미 DB에 있으니, 그냥 쿼리로 뽑으면 되지 않을까?"**\
너무나 당연하고 비용도 들지 않는 방법입니다. 하지만 이 단순함 뒤에는 결합도(Coupling)와 모니터링 (Observability)의 문제가 숨어 있었습니다.

### 실시간 집계의 한계: 읽기와 쓰기의 한계

가장 먼저 검토한 건 API 요청 시점에 실시간으로 `GROUP BY`를 수행하는 것입니다.\
하지만 10만 개 상품의 일주일치 데이터(최소 70만 행)를 매 요청마다 스캔하는 건 위험했습니다.

```sql
SELECT product_id, SUM(score) as total_score
FROM product_metrics
WHERE metric_date BETWEEN '2025-12-25' AND '2025-12-31'
GROUP BY product_id
ORDER BY total_score DESC
LIMIT 100
```

인덱스를 태워도 `GROUP BY`와 `ORDER BY` 를 활용한 쿼리를 실행했을때 Full Scan 이 발생하고, 이로인해 만일\
랭킹 조회가 몰리면 DB 리소스에 문제가 생겨서 , 정작 중요한 '주문/결제' 트랜잭션까지 문제가 될수있을거라 생각했습니다.

### Cron 스크립트: 단순 처리의 한계

그렇다면 단순히 밤에 한 번만 도는 스크립트(Cron) 로직을 구현한다고 했을때,\
`@Scheduled`나 쉘 스크립트로 구현하면 공수가 크게 발생하지 않는 작업이라 이라 생각했습니다.\
하지만 `장애 상황`과 `재처리`를 시뮬레이션해보니, 단순 스크립트의 한계가 있었습니다.

1. **상태(State)의 부재**:\
   단순 스크립트는 **"자신이 어디까지 했는지"** 기억하지 못합니다.\
   10만 건 중 9만 건을 처리하다 에러가 난다고 했을떄 처음부터 다시 돌려야 합니다. \
   아니면 "어디서부터 다시 시작해"라는 로직을 `if-else`로 직접 구현해야 하는데, \
   이는 결국 배치 프레임워크를 어설프게 다시 만드는 것이라 생각했습니다.
2. **파라미터 관리의 어려움**:\
   "저번 주 랭킹 데이터가 잘못됐어. 다시 돌려야 해."\
   이때 단순 스크립트는 코드를 수정해서 날짜를 하드코딩하거나, \
   복잡한 CLI 인자를 받아야 해서 공수가 가중될것으로 보였습니다.\
   아무리 자동화를 적용한다 했어도 날짜인자를 잘못 한다 하면 잘못된 결과를 저장하는 상황도 우려했습니다.

이번에 저에게 필요한 건 단순히 "코드를 실행해 주는 도구"가 아니라,\
**성공과 실패의 과정을 기록하고(JobRepository), 실패한 지점부터 안전하게 다시 시작할 수 있는(Restartability)** \
체계적인 시스템이였고, 그를 위해서 배치가 필요하다고 생각했습니다.

***

## 3. 배치를 선택한 기준과 구조 설계 <a href="#id-3" id="id-3"></a>

Redis의 비싼 비용과 불안정성, Cron 스크립트의 한계를 확인을 해본 결과, 결국 **Spring Batch**를 선택했습니다.

물론 앞서 이야기한 단점과 한계 이외에도 여러 스크립트 언어 기반으로 가벼운 배치 서비스를 운영하는건 적극적으로 찬성하였습니다. 하지만 스프링 배치를 이용한 **Chunk-Oriented Processing** 과 충분한 공식 문서의 풍부함을 봤을때 Spring Batch 를 선택하였습니다. 하지만 도구의 이름보다 중요한 건, **데이터의 성격**에 맞는 구조 설계라고 생각합니다.

#### 기준: 왜 배치인가?

스스로 정의한 도입 기준은 다음과 같습니다.

1. **대용량 (Volume)**: 10만 개 상품의 7일치 데이터(약 70만 행)를 한 번에 메모리에 올리지 않고, **Chunk 단위**로 나누어 처리해야 OOM(Out Of Memory)을 피할 수 있다.
2. **비주기성 (Frequency)**: 매초 바뀌는 데이터가 아니라, 주/월 단위로 "확정된 과거 데이터"를 다루므로 실시간성은 필요 없다.
3. **복구 가능성 (Recoverability)**: 언제든 특정 주차(Week)의 집계가 실패하면, 파라미터만 바꿔서 **안전하게 재실행**할 수 있어야 한다.

### 설계 Phase 1: 기반 다지기

배치를 돌리려면 먼저 데이터를 **날짜별로 쪼개서 읽을 수 있는 상태** 로 만들 필요가 있습니다.\
기존 `product_metrics` 테이블은 `product_id`만 PK로 가지고 있어, 전체 누적 데이터만 알 수 있었습니다.\
이를 해결하기 위해 복합키(Composite Key)를 도입해 **일간 집계 테이블**로 전환했습니다.

```java
// ProductMetricsId.java
@Embeddable
@EqualsAndHashCode // 복합키 필수
public class ProductMetricsId implements Serializable {
    @Column(name = "product_id")
    private Long productId;

    @Column(name = "metric_date")
    private LocalDate metricDate; // 핵심: 날짜별 분리
}


@Entity
@Getter
@Table(name = "product_metrics")
@NoArgsConstructor(access = AccessLevel.PROTECTED)
public class ProductMetricsEntity {
    // 날짜별 데이터로 관리
    @EmbeddedId
    private ProductMetricsId id;

}
```

이후에 진행할 배치 프로세스는 상품의 id 와 기준일자를 통해 **1주일치** 데이터만 가져올수 있도록 준비했습니다.

### 설계 Phase 2: 안전한 파이프라인 (Chunk Model)

배치 구조는 읽고(Read) → 계산하고(Process) → 박제한다(Write)는 배치 철학을 그대로 따랐습니다.\
특히 결과 저장을 위해 **MV(Materialized View)** 전용 테이블(`mv_product_rank_weekly`)을 별도로 설계했습니다.

```java
// WeeklyRankingJobConfig.java 
@Bean
public Step weeklyRankingStep() {
    return new StepBuilder("weeklyRankingStep", jobRepository)
        .<RankingAggregation, WeeklyRankEntity>chunk(1000, transactionManager) // 1000개씩 끊어서 처리
        .reader(weeklyMetricsReader) // DB에서 7일치 합산 (GROUP BY)
        .processor(aggregation -> {
            // 비즈니스 로직: 점수 계산 및 Entity 변환
            long totalScore = calculator.calculate(aggregation);
            return WeeklyRankEntity.of(aggregation, totalScore);
        })
        .writer(weeklyRankWriter) // MV 테이블에 저장
        .build();
}
```

* **Reader**: `GROUP BY` 쿼리로 집계 데이터를 가져옵니다.
* **Writer**: 매번 계산하는 게 아니라, 계산된 결과를 **물리 테이블(MV)에 영구 저장**합니다.\
  조회 API는 복잡한 연산 없이 이 MV 테이블만 가져와서 구성할수 있도록 준비했습니다.

이 구조를 통해, 저희는 쓰기(Batch)와 읽기(API)의 책임을 명확하게 하도록 했습니다.



### 설계 Phase 3: 테스트 불가능한 코드를 피해서

배치를 도입하며 가장 고민했던 지점은 **테스트**였습니다.\
단순 스크립트라면 "일단 돌려보고 로그 본다"가 전략이겠지만, Spring Batch는 자바 코드입니다. 테스트가 가능해야 했습니다.

하지만 배치 코드는 태생적으로 **절차지향적**입니다.\
`Step` 하나가 거대해지면, 테스트 코드는 2000줄짜리 `execute()` 메서드를 블랙박스로 검증해야 하는 괴물이 됩니다.

```java
// 나쁜 예: Step 전체를 통합 테스트로만 검증하려 할 때
@Test
void stepExecutionTest() {
    // DB 셋업, Mocking, 실행, 결과 검증... (너무 복잡함)
    jobLauncher.run(job, params);
}
```

"이게 정말 효율적인가 라는 생각을 많이 했습니다. 유지보수가 어려운 테스트를 작성하는것이 아니라 생각합니다.\
배치 프레임워크 자체(`Reader`, `Writer` 흐름)는 이미 검증된 오픈소스이고.\
우리가 검증해야 할 것은 우리가 짠 비즈니스 로직에 초점을 맞춰야한다고 봤습니다.

그래서 테스트 전략을 **이원화**했습니다.

1. **Job 통합 테스트 (Smoke Test)**:
   * "Job이 설정대로 뜨고, 끝까지 도는가?"만 확인합니다.
2. **핵심 로직 단위 테스트 (Unit Test)**:
   * 배치 로직에서 **비즈니스 계산 로직(ScoreCalculator, Processor)을** \
     **순수 자바 클래스(POJO)로 분리**했습니다.
   * Spring Context 없이, 빠른 단위 테스트로 검증하도록 만 했습니다.



```java
// 핵심 로직은 Spring 없이 테스트 가능하게 분리
@Test
void calculateScoreTest() {
    // Given
    RankingAggregation data = new RankingAggregation(...);
    // When
    long score = calculator.calculate(data);
    // Then
    assertThat(score).isEqualTo(expectedScore);
}
```

이 방식을 통해, 배치의 어려운 로직에 집중하는 대신 핵심 로직 안정성에만 집중하도록 했습니다.



네, 이해했습니다. \*\*"테스트 코드 작성조차 건너뛰고, 실행 결과와 구조적 안전장치(멱등성)에 집중했다"\*\*는 뉘앙스로 4장을 아주 솔직하고 담백하게 수정하겠습니다.

***

## 4. 구현 검증 <a href="#id-4" id="id-4"></a>

솔직히 고백하자면, 이번 배치 작업에서 거창한 통합 테스트 코드는 작성하지 않았습니다.\
배치 테스트를 짜려면 `JobLauncher`, `JobRepository`, `TransactionManager` 등 설정해야 할 게 산더미고, 정작 검증하고 싶은 건 DB 에 데이터가 잘 저장 되었는가? 정도였습니다

대신 **재실행 안전성** 두 가지에만 집중했습니다.

#### 멱등성: 몇 번을 돌려도 안전하게

PR에서 가장 신경 쓴 부분 중 하나는 \*\*재실행 가능성(Restartability)\*\*이었습니다.\
배치는 언제든 실패할 수 있고, 운영자가 수동으로 다시 돌릴 수도 있습니다.\
이때 데이터가 중복해서 쌓이면 랭킹은 엉망이 됩니다.

그래서 `WeeklyRankWriter` 내부에 **지우고 다시 쓰는** 로직을 포함시키지 않고,\
Step의 시작 부분에 **데이터 정리(Clean-up)** 단계를 명시적으로 배치했습니다.

```java
// WeeklyRankingJobConfig.java
@Bean
public Job weeklyRankingJob() {
    return new JobBuilder("weeklyRankingJob", jobRepository)
        .start(deleteOldRankingStep()) 
        .next(weeklyRankingStep())
        .build();
}
```

이 구조 덕분에, 제가 원하는 주차를 파라미터로 JOB을 매번 실행해도 결과는 항상 TOP 100만 남도록 하였습니다.

***

## 5. 마무리: 적절한 항아리의 선택 <a href="#id-5" id="id-5"></a>

Redis ZSET으로 시작해 Spring Batch로 마무리된 랭킹 시스템이었습니다.\
처음엔 "Redis 하나로 다 하면 안 되나?" 싶었지만, 결국 **데이터의 성격**이 도구를 결정했습니다.

* **찰나의 실시간성**이 필요할 땐 **Redis** (비싸지만 빠름)
* **묵직한 통계와 기록**이 필요할 땐 **Batch** (RDB를 사용해 느리지만 조회할때 캐싱 패턴 사용)

이번 작업은 단순히 기술 스택 하나를 늘린 게 아니라고 생각합니다.\
왜 이 도구를 써야 하는가를 운영 관점에서 고민해보고,\
단순하고 확실한 방법(배치, MV) 으로 풀어낸 과정이었습니다.

이제 빠른 물줄기는 Redis가, 깊은 물줄기는 Batch 서비스를 통해 나눠 담음으로서,\
각자 잘할수있는 영역의 책임을 분명하게 했습니다.

