# 내 레디스는 이정도의 값어치가 있을까?



## 서론. 이 글을 작성하게 된 이유 <a href="#undefined" id="undefined"></a>

캐시는 논리적인 개념이고, Redis는 이를 구현한 훌륭한 도구입니다.

인덱스와 MV, 빠른 응답을 위해 캐시라는 방식을 고민했고 Redis를 선택했습니다.

캐싱은 본질적으로 휘발성이기에, RDB라는 주 데이터 흐름을 캐시라는 임시 저장소로 분기하는 작업입니다. 비유하자면 캐시는 큰 물줄기를 작은 물줄기로 나누어 받아 담는 항아리이고, 서버 재시작은 그 항아리를 깨뜨리는 일입니다. 깨진 항아리의 물은 다시 채워야 하죠. 물론 보다 복잡한 기술적 개념이 있지만 생략하겠습니다.

이번 글에서는 제가 겪은 문제를 캐시 메모리라는 **항아리를 적절히 필요한 것로 채웠는지, 깨졌을 때 대비책을 마련했는지** \
돌아보는 시간을 가져보려 합니다.

## 내 데이터의 순위는 어디에서 꺼낸다음 정리해야 할까?&#x20;

자주 이용하는 데이터 현황을 실시간으로 보여주기. 한줄로 정리되는 단순한 요구사항입니다.

Kafka로 들어오는 조회, 장바구니, 구매 이벤트를 랭킹에 반영하고 사용자는 모바일, 웹에서 스크롤, 페이징하며 봅니다.

RDB에 MV 성격의 점수 테이블을 만들고 내림차순 쿼리를 짭니다.

```java
SELECT product_id, SUM(score) as total_score
FROM product_events 
WHERE date = CURDATE()
GROUP BY product_id 
ORDER BY total_score DESC 
LIMIT 100 OFFSET 900
```

**가장 큰 문제는 GROUP BY입니다.** 인덱스를 product\_id, date, score 순으로 만들어도 GROUP BY 때문에 풀스캔을 피할 수 없습니다. MySQL 옵티마이저는 GROUP BY를 먼저 처리한 뒤 ORDER BY 정렬을 합니다. 결과적으로\
**인덱스가 GROUP BY 앞에서는 무용지물**입니다.

MV(Materialized View)로 집계 테이블을 만들어 봤지만,\
실시간 Kafka 이벤트 반영이 늦어지고 페이징 깊어질수록 여전한 병목이었습니다.&#x20;

결국 관계형 DB에서 실시간 집계 + 페이징은 근본적인 한계가 있습니다.



## Redis를 선택하기 전에 세운 기준

이번 챕터는 사실 제가 이 글을 쓰게 된 근본 이유이기도 합니다. 단순히 “MySQL보다 빠르다길래 써봤다”가 아니라, \
**왜 빠른가, 그리고 정말 지금 내 문제에 맞는가?** 를 스스로 납득하고 싶었습니다.

#### 싱글 스레드인데, 왜 이렇게 빠를까

Redis는 단일 스레드로 동작합니다.\
이 한 문장만 봐도 본능적으로 의문이 들었습니다.

**멀티스레드가 더 빠른것이 아닌가?**

대부분의 애플리케이션에서 우리는 CPU 코어를 더 써서 성능을 높입니다.\
그런데 Redis는 정반대의 길을 선택하죠.

처음엔 납득이 안 됐지만, 코어 동작을 들여다보니 답은 생각보다 단순했습니다.\
멀티스레드는 스레드가 바뀔 때마다 **컨텍스트 스위칭**이라는 비용을 치릅니다.\
CPU는 상태를 저장하고 복구하느라 시간을 허비하고,\
락을 잡고 풀다 보면 Race Condition이나 Deadlock도 생깁니다.\
그런데 Redis는 이런 복잡한 과정을 싹 걷어냈습니다.

**모든 명령이 한 줄로 순차적으로 흘러갑니다.**\
그래서 `ZINCRBY` 명령을 동시에 수천 개 보내도,\
실제 Redis 내부에서는 한 스레드가 일렬로, 순서대로 처리합니다.\
그 결과 동시성과 원자성은 자연스럽게 확보되고, 오히려 더 빨라지는 결과를 얻었습니다.\
단순함으로 성능을 가져간것입니다.

***

#### epoll, 그리고 I/O 멀티플렉싱

하지만 단순히 싱글 스레드라서 빠른 건 아닙니다.\
레디스의 **I/O 멀티플렉싱**, 그중에서도 **epoll**이라는 메커니즘도 이유가 되었습니다.

기존 서버 모델은 수천 개의 네트워크 소켓을 모두 돌며\
“데이터 들어왔니?” 하고 물어봐야 했습니다. 당연히 느릴 수밖에 없죠.\
반면 epoll은 발상의 전환이었습니다.

**레디스 :** **내가 다 돌지 말고, 준비된 놈만 알려줘.**

이게 epoll의 핵심입니다.\
OS가 데이터를 준비한 소켓의 목록을 Redis에게 바로 전달합니다 이렇게 될 경우 복잡도는 O(1)에 가깝습니다.\
그래서 한 스레드만으로도 수만 개의 요청을 감시하고 처리할 수 있습니다.\
마치 웨이터 한 명이 매번 홀을 돌지 않고, 벨이 울린 테이블로만 바로 가는 구조입니다.

이 구조 덕분에 Redis는 CPU를 거의 놀리다시피 하면서도\
엄청난 양의 요청을 처리합니다. 락 경쟁은 없고, **병목의 원인은 오직 네트워크 I/O뿐 입니다.**

***

#### 구조보다 중요한 건, 내가 겪는 문제와의 적합성

epoll을 이해하니 자연스럽게 다음 생각이 들었습니다.

**“이 구조가 내가 겪고 있는 ‘실시간 랭킹’ 문제랑 어떻게 이어질까?”**

랭킹의 본질은 간단합니다.\
**점수가 들어올 때마다 순위가 즉시 바뀌는 구조.**\
RDB에서는 GROUP BY와 ORDER BY로 이걸 풀려다 매번 테이블을 다시 읽어야 하고,\
페이징이 깊어질수록 응답이 폭발적으로 느려집니다.

Redis는 이 문제를 **자료구조 설계 단계에서** 해결할 수 있습니다..\
`Sorted Set(ZSET)`은 바로 이 문제를 위한 자료구조였습니다.

```
ZADD key score member    → (score, member)로 저장 즉시 정렬
ZRANGE 0 99              → 상위 100개 O(log N)에 반환
```

내부적으로 SkipList가 정렬을 담당하고, HashMap이 빠른 조회를 돕습니다.\
점수가 바뀌면 순위도 자동으로 재계산됩니다.\
정렬된 랭킹을 별도로 캐싱하지 않아도 항상 최신 상태를 유지합니다.\
&#xNAN;**"실시간"이 구조 차원에서 보장되는 셈이죠.**

***

#### 내가 납득한 Redis의 본질

이 과정을 거치고 나니, Redis는 단순한 캐시 이상의 존재로 보였습니다.\
그건 ‘실시간 계산 엔진’ 이었습니다.

* 싱글 스레드로 복잡함을 제거하고,
* epoll로 수만 연결을 효율적으로 감시하고,
* ZSET으로 점수 기반 실시간 정렬을 위한 완벽한 추상화를 제공한다.

결국 “왜 빠른가”를 이해하니 “왜 써야 하는가”가 따라왔습니다.\
Redis는 저에게 ‘결과를 캐시하는 도구’에서\
‘지금 이 순간의 상태를 만들어내는 도구’로 인지하게 되었습니다.

***

## Z-SET으로 구현한 실시간 랭킹 구조 <a href="#id-4-zset" id="id-4-zset"></a>

#### 문제를 다시 쪼개 보기

Redis를 쓰기로 결정했다고 해서 모든 게 해결되진 않았습니다.\
‘랭킹’이라는 요구사항은 생각보다 더 세분화된 문제 덩어리였습니다.

> * 어떤 이벤트를 점수로 환산할 것인가?
> * 누적 점수는 어디까지 인정할 것인가?
> * 하루가 지나면 데이터는 어떻게 처리할 것인가?

Redis는 단순히 빠른 저장소일 뿐, 설계 방향성을 대신 정해주지 않습니다. \
저의 설계를 사용하기 위한 적합한 도구중에 하나일 뿐입니다.\
그래서 다시 문제를 잘게 쪼개면서 기준을 잡아갔습니다.

***

#### 이벤트를 점수로 바꾸는 로직

하루 동안 Kafka에서 들어오는 이벤트는 세 가지였습니다.

| 이벤트                  | 의도    | Weight | 설명            |
| -------------------- | ----- | ------ | ------------- |
| 조회(PRODUCT\_VIEW)    | 관심 단계 | 0.1    | 가장 쉽고 빈번하게 발생 |
| 좋아요(LIKE\_ACTION)    | 호감 표현 | 0.2    | 사용자의 의도 반영    |
| 구매(PAYMENT\_SUCCESS) | 실제 전환 | 0.6    | 금액 로그 기반 정규화  |

```sql
// 예시
ZINCRBY ranking:all:20251226 0.1 prod:1001
ZINCRBY ranking:all:20251226 0.2 prod:1002
ZINCRBY ranking:all:20251226 0.6*log(totalPrice+1) prod:1003
```

이 단순한 숫자 계산 하나가, MySQL에서는 수 초짜리 GROUP BY를 대체했습니다.\
레디스 z-set 을 이용해 실시간으로 점수가 더해지고, 정렬도 즉시 반영됩니다.\
결국 ‘조회에서 구매까지의 여정’을 점수 하나로 표현할 수 있었습니다.

***

### 캐시 키 전략: 날짜 단위 분리 + TTL 2일

랭킹은 하루 기준으로 쌓입니다.\
따라서 키를 `ranking:all:{yyyyMMdd}` 형식으로 만들고 **TTL 2일**을 부여했습니다.

이 설계는 두 가지 목적을 동시에 만족합니다.

* **Carry-Over(오늘 → 내일)** : 매일 23:50 상위 100개를 10% 가중치로 다음날 미리 복사
* **Fallback(오늘 → 어제)** : 자정 이후 랭킹 비어 있으면 어제 데이터로 즉시 대체

이 전략으로 하루가 바뀌는 순간 발생하던 **Cold Start** 문제를 대비 하였습니다.

***

#### 구조: Kafka → Redis → API

이렇게 추가 및 구현한 구조는 다음과 같습니다.

```
Kafka Consumer
   ↓
EventProcessingFacade (유스케이스 조율)
   ↓
RankingService (ZINCRBY 수행)
   ↓
Redis ZSET (정렬 저장)
```

그리고 API 서버에서 다시 데이터를 불러올 때는

```
ProductFacade → RankingRedisService → ZRANGE key offset limit
```

으로 일관되게 분리했습니다.\
Kafka, Redis, API가 각각 “한 가지 일만” 하도록 구성한 것이 핵심이었습니다.

#### 남은 고민

이 구조가 절대적으로 완벽하진 않습니다.\
레디스가 종료되면 아예 해당 데이터는 사라지게 될것이고, \
다양한 랭킹 유형이 정의되면 콜드 스타트를 해결하기 위한 스케줄러도 가중될것입니다.\
ZSET의 멤버 수가 수십만을 넘어가면, `ZRANGE` 나 `ZREVRANGE` 자체가 부담이 가중 될것입니다.\
Redis가 만능이라는 착각에서 벗어나,\
‘언제 어디까지 이 구조를 끌고 갈 수 있을까’를 계속 점검 중입니다.

#### 현재 구조에 대한 정리

이제 저에게 Redis는 단순 캐시가 아니라,\
**실시간 데이터를 계산하고 표현하는 레이어**로 자리 잡았습니다.\
ZSET 하나로 GROUP BY, ORDER BY, 페이징, 정렬을 모두 대체할 수 있었고,\
MySQL이 버티지 못하던 실시간성의 벽을 부드럽게 넘었습니다.

다만 이 흐름이 또 다른 병목을 만들 수도 있습니다.\
Redis의 강점이 어디까지 유지되고, 언젠가 어떤 순간 ‘느려지기 시작할지’를\
직접 운영하며 확인하고 있습니다.



